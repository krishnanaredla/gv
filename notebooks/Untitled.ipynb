{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame([{'id': 1, 'value': 1,'amount':2}, {'id': 2, 'value': 2,'amount':3}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "from typing import List\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.column import Column\n",
    "from pyspark.sql import Window\n",
    "import datetime\n",
    "import decimal\n",
    "from typing import List, Dict, Union, Any\n",
    "\n",
    "class Orca(object):\n",
    "    _type_mappings = {\n",
    "    type(None): NullType,\n",
    "    bool: BooleanType,\n",
    "    int: LongType,\n",
    "    float: DoubleType,\n",
    "    str: StringType,\n",
    "    bytearray: BinaryType,\n",
    "    decimal.Decimal: DecimalType,\n",
    "    datetime.date: DateType,\n",
    "    datetime.datetime: TimestampType,\n",
    "    datetime.time: TimestampType,\n",
    "    bytes: BinaryType,}\n",
    "    def __init__(self,df):\n",
    "        self.df = df\n",
    "    def addColumnSuffix(\n",
    "    self, suffix: str = \"suffix\", colsList: List = []\n",
    ") -> DataFrame:\n",
    "        if not colsList:\n",
    "            colsList = self.df.columns\n",
    "\n",
    "        def _keyExists(s):\n",
    "            return s in colsList\n",
    "\n",
    "        cols = list(\n",
    "            map(\n",
    "                lambda col_name: col(col_name).alias(\"{0}_{1}\".format(col_name, suffix))\n",
    "                if _keyExists(col_name)\n",
    "                else F.col(col_name),\n",
    "                self.df.columns,\n",
    "            )\n",
    "        )\n",
    "        return Orca(self.df.select(*cols))\n",
    "    def returnDF(self):\n",
    "        return self.df\n",
    "    def addColumnPrefix(\n",
    "    self, prefix: str , colsList: List \n",
    ") -> DataFrame:\n",
    "    \n",
    "        if not colsList:\n",
    "            colsList = self.df.columns\n",
    "\n",
    "        def _keyExists(s):\n",
    "            return s in colsList\n",
    "\n",
    "        cols = list(\n",
    "            map(\n",
    "                lambda col_name: F.col(col_name).alias(\"{0}_{1}\".format(prefix, col_name))\n",
    "                if _keyExists(col_name)\n",
    "                else F.col(col_name),\n",
    "                self.df.columns,\n",
    "            )\n",
    "        )\n",
    "        return Orca(self.df.select(*cols))\n",
    "    def dedupsByRank(\n",
    "    self,\n",
    "    partitionCols: List,\n",
    "    orderCols: Union[List, Dict[str, List]],\n",
    "    rankType:Column = row_number(),\n",
    ") -> DataFrame:\n",
    "        orderCols = (\n",
    "            {\"columns\": list(orderCols), \"asc\": [], \"desc\": []}\n",
    "            if isinstance(orderCols, list)\n",
    "            else orderCols\n",
    "        )\n",
    "        _ = (\n",
    "            lambda col_name: col(col_name).asc()\n",
    "            if col_name in orderCols[\"asc\"]\n",
    "            else (col(col_name).desc() if col_name in orderCols[\"desc\"] else col(col_name))\n",
    "        )\n",
    "        windowBy = Window.partitionBy(\n",
    "            *list(map(lambda col_name: col(col_name), partitionCols))\n",
    "        ).orderBy(*list(map(lambda col_name: _(col_name), orderCols['columns'])))\n",
    "        return Orca(\n",
    "            self.df.withColumn(\"rank\", rankType.over(windowBy))\n",
    "            .filter(col(\"rank\") == 1)\n",
    "            .drop(\"rank\")\n",
    "        )\n",
    "    def selectByDtype(self, dtypes: Any) -> DataFrame:\n",
    "        if isinstance(dtypes, list):\n",
    "            for val in range(len(dtypes)):\n",
    "                if dtypes[val] in self._type_mappings.keys():\n",
    "                    dtypes[val] = self._type_mappings[dtypes[val]]\n",
    "            dtypes = tuple(dtypes)\n",
    "        elif dtypes in self._type_mappings.keys():\n",
    "            dtypes = self._type_mappings[dtypes]\n",
    "        cols = list(\n",
    "            filter(\n",
    "                None.__ne__,\n",
    "                list(\n",
    "                    map(\n",
    "                        lambda field: field.name\n",
    "                        if isinstance(field.dataType, dtypes)\n",
    "                        else None,\n",
    "                        self.df.schema,\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "        return Orca(self.df.select(*cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(r'C:\\work\\python-packages\\orca\\data\\membership.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  20000\n",
      "Schema:\n",
      "root\n",
      " |-- uniqueID: long (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- recID: string (nullable = true)\n",
      " |-- cost: double (nullable = true)\n",
      " |-- dates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Count: ',df.count())\n",
    "print(\"Schema:\")\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert spark dataframe into Orca\n",
    "od = Orca(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "orderCols = {'columns' : ['dates','cost'],'asc' : ['dates'],'desc' : ['cost']}\n",
    "\n",
    "# Can apply all the available Orca functions\n",
    "odf = od.dedupsByRank(['uniqueID'],orderCols)\\ # apply deduplication by rank\n",
    "       .selectByDtype(str).returnDF() # Select columns of only string type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count:  1000\n",
      "Schema:\n",
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- recID: string (nullable = true)\n",
      " |-- dates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Count: ',odf.count())\n",
    "print(\"Schema:\")\n",
    "odf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+---------+-------------------+\n",
      "|             Name|    recID|              dates|\n",
      "+-----------------+---------+-------------------+\n",
      "|     Bruno Sparks|ID5342509|2000-10-19 10:00:27|\n",
      "|    Markus Kelley|ID9563493|2003-06-04 01:08:37|\n",
      "|    Isidro Reeves|ID2380131|2001-06-17 07:19:24|\n",
      "|    Kurtis Garcia|ID3464937|2000-04-21 15:01:52|\n",
      "|  Lavonia Summers|ID1344139|2000-05-10 04:12:18|\n",
      "|    Arlie Bernard|ID3411614|2001-07-19 13:01:53|\n",
      "|      Lizeth Lara|ID6967628|2000-04-21 23:53:27|\n",
      "|  Isaiah Mcintyre|ID3409715|2005-07-09 01:59:49|\n",
      "|     Roni Ramirez|ID4970503|2000-11-29 03:52:38|\n",
      "|       Leon Burch|ID9247350|2001-07-30 12:25:34|\n",
      "| Margaretta Kelly|ID7673732|2000-09-19 17:03:40|\n",
      "|Letisha Blackburn|ID2437465|2001-02-26 04:44:24|\n",
      "|  Somer Patterson|ID0556149|2000-08-27 17:40:15|\n",
      "|       Damon Pace|ID3268057|2001-02-22 00:31:44|\n",
      "|     Jude Camacho|ID5081762|2001-04-20 05:37:06|\n",
      "|    Cythia Reeves|ID9220392|2000-04-19 17:12:37|\n",
      "|     Halina Hardy|ID5092522|2000-04-15 21:11:47|\n",
      "|    Theo Shepherd|ID9556455|2001-04-19 05:25:36|\n",
      "|     Gaston Hicks|ID9948462|2000-08-14 17:42:42|\n",
      "|   Jerrod Mercado|ID6803501|2001-04-27 16:53:06|\n",
      "+-----------------+---------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- recID: string (nullable = true)\n",
      " |-- dates: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0-------------------\n",
      " prefix_amount_suffix | 2   \n",
      " prefix_id_suffix     | 1   \n",
      " prefix_value_suffix  | 1   \n",
      "-RECORD 1-------------------\n",
      " prefix_amount_suffix | 3   \n",
      " prefix_id_suffix     | 2   \n",
      " prefix_value_suffix  | 2   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(df._jdf.showString(20, 20, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
